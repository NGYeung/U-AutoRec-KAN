{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6Ga8eXaqFxm"
      },
      "source": [
        "**Before running this notebook, please add a shortcut of the RecSys folder to the root directory of your drive (MyDrive)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ7z6B42a9Mo",
        "outputId": "350b2ae8-5fa5-4607-b561-8c1dc3c301e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYCdTXr6oRbJ"
      },
      "source": [
        "The following is for the KAN layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iCsxdjNDzbsm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199e2c8a-8753-43ec-a0c2-c7f614302617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fast-kan'...\n",
            "remote: Enumerating objects: 202, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 202 (delta 52), reused 62 (delta 44), pack-reused 124 (from 1)\u001b[K\n",
            "Receiving objects: 100% (202/202), 420.57 KiB | 1.83 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n",
            "Processing ./fast-kan\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastkan==0.0.1) (1.26.4)\n",
            "Building wheels for collected packages: fastkan\n",
            "  Building wheel for fastkan (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastkan: filename=fastkan-0.0.1-py3-none-any.whl size=11560 sha256=dff3d9df3946ad947baccc370c7f645c07fcfd479841c4912ebd49221bc6448e\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/67/af/0e9541499b9ccc4465dae8c80e40769cc637277b82bcfeb08b\n",
            "Successfully built fastkan\n",
            "Installing collected packages: fastkan\n",
            "Successfully installed fastkan-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ZiyaoLi/fast-kan\n",
        "\n",
        "!pip install '/content/fast-kan/.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Br9CQ3F3ajGr"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/RecSys/')\n",
        "sys.path.append('/content/drive/MyDrive/RecSys/model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VkelKA4CZRZz"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random as rnd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Subset,random_split,default_collate\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import logging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nf267ZqmZRZz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from numba import jit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "eomVLTrYZRZ0"
      },
      "outputs": [],
      "source": [
        "from AutoRec_KAN import AE_KAN\n",
        "from MovieLens_4Colab import Movie_1M, CombinedDataset, preprocess_100K\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tUiGuM6pTjLo"
      },
      "outputs": [],
      "source": [
        "def custom_collate(batch, batch_size, dataset):\n",
        "    if len(batch) < batch_size:\n",
        "\n",
        "        additional_samples_needed = batch_size - len(batch)\n",
        "        indices = np.random.choice(len(dataset), additional_samples_needed)\n",
        "        additional_data = [dataset[idx] for idx in indices]\n",
        "        batch.extend(additional_data)\n",
        "    return default_collate(batch)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(4224)\n",
        "\n",
        "np.random.seed(4224)"
      ],
      "metadata": {
        "id": "GT_S4lkQNPax"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is for construction 9 different 9:1 train-test splits."
      ],
      "metadata": {
        "id": "6g5b1wADvZXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset = Movie_1M()"
      ],
      "metadata": {
        "id": "vi2L_nAdbamm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H7XR334kFQ1W"
      },
      "outputs": [],
      "source": [
        "#len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cross_validation\n",
        "\n",
        "#for sd in [1,2,3,5,8,13,21,34]:\n",
        "#\n",
        "#  indices = np.random.permutation(len(dataset))\n",
        "#  train_index = indices[:int(round(0.9*len(dataset)))]\n",
        "#  train_rating, train_mask, test_rating, test_mask = dataset.preprocessor(train_index, fourier = False)\n",
        "\n",
        "#  torch.save(train_mask, '/content/drive/MyDrive/RecSys/1m_train_mask_'+str(sd)+'.pt')\n",
        "#  torch.save(train_rating, '/content/drive/MyDrive/RecSys/1m_train_rating_'+str(sd)+'.pt')\n",
        "\n",
        "#  torch.save(test_rating, '/content/drive/MyDrive/RecSys/1m_test_rating_'+str(sd)+'.pt')\n",
        "#  torch.save(test_mask, '/content/drive/MyDrive/RecSys/1m_test_mask_'+str(sd)+'.pt')\n",
        "\n"
      ],
      "metadata": {
        "id": "defAdfwAfeBw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.model_selection import KFold\n"
      ],
      "metadata": {
        "id": "Z5MHuJWDutkX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kf = KFold(n_splits=10, shuffle=True, random_state=42)  # Set a random seed for reproducibility\n",
        "\n",
        "# Enumerate over each split\n",
        "'''\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(dataset)):\n",
        "    train_rating, train_mask, test_rating, test_mask = dataset.preprocessor(train_index, fourier=False)\n",
        "\n",
        "    torch.save(train_mask, f'/content/drive/MyDrive/RecSys/1m_train_mask_fold_{fold}.pt')\n",
        "    torch.save(train_rating, f'/content/drive/MyDrive/RecSys/1m_train_rating_fold_{fold}.pt')\n",
        "\n",
        "    torch.save(test_rating, f'/content/drive/MyDrive/RecSys/1m_test_rating_fold_{fold}.pt')\n",
        "    torch.save(test_mask, f'/content/drive/MyDrive/RecSys/1m_test_mask_fold_{fold}.pt')\n",
        "'''"
      ],
      "metadata": {
        "id": "fDutgoH2u75Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9aa7accf-5c73-460e-cdb4-7b7682bb4a3c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor fold, (train_index, test_index) in enumerate(kf.split(dataset)):\\n    train_rating, train_mask, test_rating, test_mask = dataset.preprocessor(train_index, fourier=False)\\n\\n    torch.save(train_mask, f'/content/drive/MyDrive/RecSys/1m_train_mask_fold_{fold}.pt')\\n    torch.save(train_rating, f'/content/drive/MyDrive/RecSys/1m_train_rating_fold_{fold}.pt')\\n\\n    torch.save(test_rating, f'/content/drive/MyDrive/RecSys/1m_test_rating_fold_{fold}.pt')\\n    torch.save(test_mask, f'/content/drive/MyDrive/RecSys/1m_test_mask_fold_{fold}.pt')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y6o4RHmM8OLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f76ad6ec-bca1-4809-b4d7-a8fb36a23196"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \t ----------- Model Loaded ------------\n",
            "\t *Total Params* =  36439504\n",
            "\t *Trainable Params* =  36439488\n"
          ]
        }
      ],
      "source": [
        "model = AE_KAN(configuration_file = '/content/drive/MyDrive/RecSys/MovieLens1M.yaml')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2YGgiOwR0quh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SBACarmoWKP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y089h_8AocWF"
      },
      "source": [
        "The following blocks are all for data pre-processing. Change the random seed to change the train/test sets for validation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fold = 9"
      ],
      "metadata": {
        "id": "Pei9Lq9QvMET"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xj62SfllFI3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4448e6-1c2c-4dc1-be4f-c73f20aad845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-078528d1d7e5>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_mask = torch.load(f'/content/drive/MyDrive/RecSys/1m_train_mask_fold_{fold}.pt')\n",
            "<ipython-input-16-078528d1d7e5>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  train_rating = torch.load(f'/content/drive/MyDrive/RecSys/1m_train_rating_fold_{fold}.pt')\n",
            "<ipython-input-16-078528d1d7e5>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_rating = torch.load(f'/content/drive/MyDrive/RecSys/1m_test_rating_fold_{fold}.pt')\n",
            "<ipython-input-16-078528d1d7e5>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  test_mask = torch.load(f'/content/drive/MyDrive/RecSys/1m_test_mask_fold_{fold}.pt')\n"
          ]
        }
      ],
      "source": [
        "train_mask = torch.load(f'/content/drive/MyDrive/RecSys/1m_train_mask_fold_{fold}.pt')\n",
        "train_rating = torch.load(f'/content/drive/MyDrive/RecSys/1m_train_rating_fold_{fold}.pt')\n",
        "\n",
        "test_rating = torch.load(f'/content/drive/MyDrive/RecSys/1m_test_rating_fold_{fold}.pt')\n",
        "test_mask = torch.load(f'/content/drive/MyDrive/RecSys/1m_test_mask_fold_{fold}.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Eo5rc6UFAawP"
      },
      "outputs": [],
      "source": [
        "train_rating = torch.tensor(train_rating)\n",
        "train_mask = torch.tensor(train_mask)\n",
        "test_rating = torch.tensor(test_rating)\n",
        "test_mask = torch.tensor(test_mask)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXeyOvFnsnbI"
      },
      "source": [
        "**Re-run the following codes for Cross-Validation after running new dataset construction codes at the bottom.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "kjrHOUkmzQhL"
      },
      "outputs": [],
      "source": [
        "batch_size = model.batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6_DSQbYAl22F"
      },
      "outputs": [],
      "source": [
        "combineset = CombinedDataset(train_rating, train_mask)\n",
        "combine_testset = CombinedDataset(test_rating, test_mask)\n",
        "dataset = DataLoader(combineset, batch_size = batch_size, shuffle = True,\n",
        "                     collate_fn=lambda x: custom_collate(x, batch_size, combineset))\n",
        "test_dataset = DataLoader(combine_testset, batch_size = batch_size, shuffle = False,\n",
        "                     collate_fn=lambda x: custom_collate(x, batch_size, combineset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agI6mFnVvR-g"
      },
      "source": [
        "### Remember to set a unique run_id to make fine-tuning easer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FLzinWKtZRZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec98c1f7-57ff-4f86-dad6-c275b9410f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 12/12 [00:02<00:00,  5.50batch/s, loss=0.21]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 1, Average Training RMSE = 2.0473, \"Accuracy\" = 0.2271\n",
            "\t Training time for current epoch: 2.19 seconds\n",
            "\t RMSE on testing set : 1.5866, RMSE (rounded): 1.6157 , MAE: 1.2655 , Accuracy: 0.2487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 12/12 [00:01<00:00, 10.96batch/s, loss=0.136]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 2, Average Training RMSE = 1.4073, \"Accuracy\" = 0.2978\n",
            "\t Training time for current epoch: 1.1 seconds\n",
            "\t RMSE on testing set : 1.2782, RMSE (rounded): 1.3113 , MAE: 1.0181 , Accuracy: 0.3046\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 12/12 [00:01<00:00, 11.68batch/s, loss=0.113]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 3, Average Training RMSE = 1.2, \"Accuracy\" = 0.3314\n",
            "\t Training time for current epoch: 1.03 seconds\n",
            "\t RMSE on testing set : 1.164, RMSE (rounded): 1.1988 , MAE: 0.9324 , Accuracy: 0.328\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 12/12 [00:00<00:00, 12.17batch/s, loss=0.101]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 4, Average Training RMSE = 1.1105, \"Accuracy\" = 0.352\n",
            "\t Training time for current epoch: 0.99 seconds\n",
            "\t RMSE on testing set : 1.103, RMSE (rounded): 1.1396 , MAE: 0.8806 , Accuracy: 0.3476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 12/12 [00:00<00:00, 12.67batch/s, loss=0.092]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 5, Average Training RMSE = 1.0633, \"Accuracy\" = 0.3659\n",
            "\t Training time for current epoch: 0.95 seconds\n",
            "\t RMSE on testing set : 1.0506, RMSE (rounded): 1.0878 , MAE: 0.8424 , Accuracy: 0.3596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 12/12 [00:01<00:00, 10.70batch/s, loss=0.0851]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 6, Average Training RMSE = 1.0218, \"Accuracy\" = 0.381\n",
            "\t Training time for current epoch: 1.13 seconds\n",
            "\t RMSE on testing set : 1.0103, RMSE (rounded): 1.0515 , MAE: 0.8085 , Accuracy: 0.3746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 12/12 [00:00<00:00, 12.49batch/s, loss=0.0785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 7, Average Training RMSE = 0.984, \"Accuracy\" = 0.3945\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.9704, RMSE (rounded): 1.0118 , MAE: 0.7686 , Accuracy: 0.4005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 12/12 [00:00<00:00, 12.50batch/s, loss=0.0728]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 8, Average Training RMSE = 0.9553, \"Accuracy\" = 0.4056\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.9346, RMSE (rounded): 0.978 , MAE: 0.7437 , Accuracy: 0.4069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 12/12 [00:00<00:00, 12.24batch/s, loss=0.0718]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 9, Average Training RMSE = 0.929, \"Accuracy\" = 0.4157\n",
            "\t Training time for current epoch: 0.99 seconds\n",
            "\t RMSE on testing set : 0.9285, RMSE (rounded): 0.9719 , MAE: 0.738 , Accuracy: 0.4124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 12/12 [00:00<00:00, 12.38batch/s, loss=0.0677]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 10, Average Training RMSE = 0.9222, \"Accuracy\" = 0.4201\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.9013, RMSE (rounded): 0.9456 , MAE: 0.7194 , Accuracy: 0.4188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11: 100%|██████████| 12/12 [00:01<00:00, 11.34batch/s, loss=0.065]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 11, Average Training RMSE = 0.9008, \"Accuracy\" = 0.4291\n",
            "\t Training time for current epoch: 1.06 seconds\n",
            "\t RMSE on testing set : 0.883, RMSE (rounded): 0.9294 , MAE: 0.6938 , Accuracy: 0.4427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12: 100%|██████████| 12/12 [00:01<00:00, 11.78batch/s, loss=0.0654]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 12, Average Training RMSE = 0.8812, \"Accuracy\" = 0.4361\n",
            "\t Training time for current epoch: 1.02 seconds\n",
            "\t RMSE on testing set : 0.8856, RMSE (rounded): 0.931 , MAE: 0.702 , Accuracy: 0.4326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13: 100%|██████████| 12/12 [00:01<00:00, 11.56batch/s, loss=0.0618]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 13, Average Training RMSE = 0.8871, \"Accuracy\" = 0.4322\n",
            "\t Training time for current epoch: 1.04 seconds\n",
            "\t RMSE on testing set : 0.8613, RMSE (rounded): 0.9078 , MAE: 0.6825 , Accuracy: 0.4447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14: 100%|██████████| 12/12 [00:00<00:00, 12.46batch/s, loss=0.0669]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 14, Average Training RMSE = 0.887, \"Accuracy\" = 0.435\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.8958, RMSE (rounded): 0.942 , MAE: 0.7108 , Accuracy: 0.4245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15: 100%|██████████| 12/12 [00:00<00:00, 12.41batch/s, loss=0.0573]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 15, Average Training RMSE = 0.8551, \"Accuracy\" = 0.4503\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.8293, RMSE (rounded): 0.8766 , MAE: 0.6583 , Accuracy: 0.4577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16: 100%|██████████| 12/12 [00:00<00:00, 12.47batch/s, loss=0.0565]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 16, Average Training RMSE = 0.8207, \"Accuracy\" = 0.4659\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.8234, RMSE (rounded): 0.872 , MAE: 0.6504 , Accuracy: 0.4663\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17: 100%|██████████| 12/12 [00:00<00:00, 12.50batch/s, loss=0.0563]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 17, Average Training RMSE = 0.8105, \"Accuracy\" = 0.4708\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.8219, RMSE (rounded): 0.871 , MAE: 0.6504 , Accuracy: 0.463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18: 100%|██████████| 12/12 [00:00<00:00, 12.12batch/s, loss=0.0518]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 18, Average Training RMSE = 0.8013, \"Accuracy\" = 0.4771\n",
            "\t Training time for current epoch: 1.0 seconds\n",
            "\t RMSE on testing set : 0.7886, RMSE (rounded): 0.8386 , MAE: 0.6227 , Accuracy: 0.4839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19: 100%|██████████| 12/12 [00:01<00:00, 11.78batch/s, loss=0.0517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 19, Average Training RMSE = 0.8001, \"Accuracy\" = 0.4776\n",
            "\t Training time for current epoch: 1.03 seconds\n",
            "\t RMSE on testing set : 0.7878, RMSE (rounded): 0.8402 , MAE: 0.6214 , Accuracy: 0.4836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20: 100%|██████████| 12/12 [00:00<00:00, 12.43batch/s, loss=0.054]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 20, Average Training RMSE = 0.8001, \"Accuracy\" = 0.4786\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.8047, RMSE (rounded): 0.8557 , MAE: 0.6343 , Accuracy: 0.4766\n",
            "checkpoint saved at epoch 20.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21: 100%|██████████| 12/12 [00:01<00:00, 10.08batch/s, loss=0.0537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 21, Average Training RMSE = 0.8006, \"Accuracy\" = 0.4781\n",
            "\t Training time for current epoch: 1.2 seconds\n",
            "\t RMSE on testing set : 0.8027, RMSE (rounded): 0.8555 , MAE: 0.6329 , Accuracy: 0.4753\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22: 100%|██████████| 12/12 [00:01<00:00, 11.13batch/s, loss=0.0552]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 22, Average Training RMSE = 0.8009, \"Accuracy\" = 0.478\n",
            "\t Training time for current epoch: 1.09 seconds\n",
            "\t RMSE on testing set : 0.8139, RMSE (rounded): 0.8638 , MAE: 0.6431 , Accuracy: 0.4703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23: 100%|██████████| 12/12 [00:01<00:00, 10.17batch/s, loss=0.0541]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 23, Average Training RMSE = 0.8009, \"Accuracy\" = 0.478\n",
            "\t Training time for current epoch: 1.19 seconds\n",
            "\t RMSE on testing set : 0.8059, RMSE (rounded): 0.8568 , MAE: 0.6384 , Accuracy: 0.4707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24: 100%|██████████| 12/12 [00:01<00:00, 10.18batch/s, loss=0.0537]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 24, Average Training RMSE = 0.7996, \"Accuracy\" = 0.478\n",
            "\t Training time for current epoch: 1.18 seconds\n",
            "\t RMSE on testing set : 0.8029, RMSE (rounded): 0.8544 , MAE: 0.6363 , Accuracy: 0.4709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25: 100%|██████████| 12/12 [00:00<00:00, 12.59batch/s, loss=0.0517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 25, Average Training RMSE = 0.7993, \"Accuracy\" = 0.4789\n",
            "\t Training time for current epoch: 0.96 seconds\n",
            "\t RMSE on testing set : 0.788, RMSE (rounded): 0.8403 , MAE: 0.6213 , Accuracy: 0.4836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26: 100%|██████████| 12/12 [00:00<00:00, 12.33batch/s, loss=0.0531]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 26, Average Training RMSE = 0.8007, \"Accuracy\" = 0.4781\n",
            "\t Training time for current epoch: 0.98 seconds\n",
            "\t RMSE on testing set : 0.7985, RMSE (rounded): 0.8492 , MAE: 0.6309 , Accuracy: 0.4772\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27: 100%|██████████| 12/12 [00:00<00:00, 12.46batch/s, loss=0.0535]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 27, Average Training RMSE = 0.8005, \"Accuracy\" = 0.4774\n",
            "\t Training time for current epoch: 0.97 seconds\n",
            "\t RMSE on testing set : 0.8009, RMSE (rounded): 0.8528 , MAE: 0.6323 , Accuracy: 0.4759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28: 100%|██████████| 12/12 [00:01<00:00, 11.27batch/s, loss=0.052]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 28, Average Training RMSE = 0.7997, \"Accuracy\" = 0.4782\n",
            "\t Training time for current epoch: 1.07 seconds\n",
            "\t RMSE on testing set : 0.7901, RMSE (rounded): 0.8409 , MAE: 0.6243 , Accuracy: 0.4807\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29: 100%|██████████| 12/12 [00:01<00:00, 11.49batch/s, loss=0.0536]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 29, Average Training RMSE = 0.8001, \"Accuracy\" = 0.4789\n",
            "\t Training time for current epoch: 1.05 seconds\n",
            "\t RMSE on testing set : 0.802, RMSE (rounded): 0.8524 , MAE: 0.6336 , Accuracy: 0.4765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30: 100%|██████████| 12/12 [00:01<00:00, 10.42batch/s, loss=0.0546]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t Epoch : 30, Average Training RMSE = 0.8006, \"Accuracy\" = 0.478\n",
            "\t Training time for current epoch: 1.16 seconds\n",
            "\t RMSE on testing set : 0.8091, RMSE (rounded): 0.8592 , MAE: 0.6404 , Accuracy: 0.4682\n"
          ]
        }
      ],
      "source": [
        "model.train(dataset, test_dataset, epoch =30)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "onaX3dPd0y3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0767aa8-7ce0-4e8d-a805-2917e7cd1c30"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIVn5aZgqN4e"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}